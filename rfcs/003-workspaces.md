# Workspaces

# Summary

Run persistent containers for users with web frontends, like VS Code and Jupyter Notebooks.

# Motivation and background

PrairieLearn currently allows code editing using an in-page ACE Editor and can compile and test code via external graders, which take student code and instructor-provided test code and execute them in an instructor-defined container, returning the test results back to the student. While excellent for testing small code snippets, this is not a very flexible environment for writing and debugging more complex programs.

This RFC proposes to give students persistent remote containers (called _Workspaces_) to work in, configured by instructors to provide a per-question environment with a specific set of compilers, debuggers, editors, etc. This remote container would be accessed via a web-based frontend, such as VS Code or Jupyter Notebooks.

Goals:
* Workspaces should be instructor-defined on a per-question basis.
* Workspaces should launch from a PL question with a set of initial files in the home directory, which may be dynamically generated by the question `server.py` code.
    * Workspaces should retain a readonly copy of these initial files to allow the student to reference/restore the initial state.
* The workspace should be accessible by the student via a web frontend (e.g., VS Code) that is served out of the workspace container.
* The student should have complete freedom to use the workspace as a development environment, including compiling and executing code.
* The files in the container home directory should be frequently autosaved to a persistent store, in case of container crashes (e.g., fork bombs).
* At any time, the student should be able to trigger a "Grade" action, which will pull an instructor-defined set of files from the container and run the usual PL grading code (either internal or external graders).
* Containers should auto-terminate after a period of inactivity (or force-terminated by the student), but should be able to be re-launched with the persistent home-directory files restored.

# Proposed solution

The server architecture has three conceptual components. The MVP will implement them in two servers:
1. PL main servers (possibly refactored in the future)
    * Web servers: render questions for the student with a "launch workspace" button in them.
    * Manager servers: coordinate the launching of workspaces and proxy all traffic from the student browser through to the host machines.
2. Host servers: run the actual containers.

These three components are implemented within the main PL executable, but for deployment we can run different fleets of servers that use a `config` option to only turn on specific functionality.

## How this works

* When we want to launch a container, we bundle files, upload to S3, download to worker, spin up a container with files mounted to a known good location.
* Run filesystem watcher on mounted directory.
* When files change, we’ll do two things:
    * We’ll upload the workspace state to S3.
    * We’ll push the submission state into the database (somewhere, tbd) and store errors too?

## Frontend

* We’ll serve the page as two parts:
    * An “outer part” that PrairieLearn controls - this gives us a place to show save status, and potentially show a grade button and immediate feedback in the long run. Can also show “I’ve bricked my container, pls help” button.
    * An “inner part”, which is the page served by the container.

## Workspace container orchestration

* On the main server:
    * When we create a variant, we (maybe) create a workspace session (if it’s enabled for that question). This is at this point just an entry in a database table somewhere.
    * We render some kind of button to launch a workspace instance for that session.
    * The user clicks on that button.
    * We get a request for a particular workspace instance.
    * We check the authorization cookies to verify that the requesting user matches the authorized user for this workspace.
    * Routes:
        * `/workspace/[uuid]` (referred to as `workspace_url` later in this document) - serves basic outer frame markup
        * `/workspace/[uuid]/frame/*` - serves resources for outer frame
        * `/workspace/[uuid]/heartbeat`
        * `/workspace/[uuid]/container/*` - proxy `*` to inner frame
* On the host:
    * `/workspace/[uuid]/workspace/*` goes to the host that’s running this container.
    * Within the host, we’ll proxy that to the appropriate container.
    * Each container will probably need port 80 bound to some random, unique port that we can target for forwards.
    * The host will listen for three types of signals: launch, sync, and kill container.
* How to map requests to hosts?
    * Hosts table that stores current information about each host VM.
* How do we kill off old containers?
    * Containers are killed after either:
        * We don’t receive N heartbeats in a row.
        * The user hasn’t saved for X amount of time.

Need to make sure that cookies are inaccessible to client-side code (https://github.com/PrairieLearn/PrairieLearn/issues/2503) and on the server (we need to configure our proxy to strip out at least the Cookie header, if not more things).

## Design

### Database

* `questions`
  * Add a new `workspace_image` column
* `workspace_hosts`:
  * `id`: a unique ID for this host
  * `instance_id`: the AWS instance ID for this host
  * `hostname`: the hostname (IP address, DNS address, etc) for this host
* `workspaces`: new tables
  * `variant_id`: Question variant we're associated with
  * `id`: a unique ID for this workspace
  * `s3_bucket`: The S3 bucket that this workspace's state lives in
  * `s3_root_key`: The root "path" within the S3 bucket
  * `workspace_host_id` (nullable): The ID of the host that this workspace container is running on, if any
  * `state`: reflects the "state" of this workspace; one of the following:
    * `uninitialized`: no resources have been created for this workspace yet; can transition to `initializing`
    * `stopped`: S3 resources for the workspace exist, but it is not running on a particular machine; can transition to `launching`
    * `launching`: we are allocating a host for this workspace and starting the appropriate container on that host; can transition to `running` or `stopped` (if launching fails)
    * `running`: the container for this workspace is running; can transition to `stopped`
* `workspace_logs`: notable events/messages assocaiated with a particular workspace (state transitions, errors, explicit restarts, etc.)
  * `workspace_id`: ID of the associated workspace
  * `timestamp`: (workshop name for consistency with rest of PL): timestamp of the event
  * `message`: string message
  * `level`: the level of this particular log

### Questions

Course staff will declare workspace config per question via `workspace` in `info.json`. To begin, the only option will be an image:

```json
{
    "workspace": {
        "image": "some-docker-image-name"
    }
}
```

The home directory in the workspace will be determined by the `workspace` directory inside a question directory. In the future, we'll add the ability to dynamically generate files via `server.py` and place them into the home directory. This is not part of the MVP.

```
questions
`-- myquestion
    +-- info.json
    +-- question.html
    +-- server.py
    +-- clientFilesQuestion
    +-- tests
    |   +-- correct_answer.c
    |   `-- test_run.py
    |
    `-- workspace
        +-- .bashrc
        +-- starter_code.h
        `-- starter_code.c
```

The workspace image name will need to be synced to the `questions` table via the usual syncing code. We should use a new `workspace_image` column.

### Student-facing question interface

> What happens when we render a question with an associated workspace?

When a new variant of a question is created, the main server will create a corresponding workspace in the database associated with that particular variant. This database entry will contain a unique hash/id/something. However, we're not going to actually provision any containers, etc. for this workspace just yet. The `state` of the new workspace row will be `uninitialized`.

We'll introduce a new `<pl-workspace>` element that renders (to start with) a "Launch workspace" button. We should introduce a new `workspace_url` to `data.options`, and this element (or potentially other elements) can use this to render a button. `workspace_url` will be something of the form `/pl/[garbage]/workspace/[workspace_id]`, where `[garbage]` corresponds to the different places that questions can be accessed from (instructor question, student variant, maybe others?).

When this button is clicked, the URL at `workspace_url` will be opened in a new tab.

### Accessing a workspace

> What happens when a user lands on a `workspace_url`?

`workspace_url` pages will be served by the main PrairieLearn server (someday, we could split this into a separate autoscaled component).

When the main server gets a request to this url, we'll first check if we have an existing instance of a workspace by checking the `state` column of the appropriate workspace. There will be three cases here:

#### Workspace is in state `uninitialized`

* Respond to the request with the basic markup for the outer frame
* Begin a transaction
  * Obtain a lock on the row in the `workspaces` table
  * Create archive of home directory
  * Upload to appropriate key in S3: `workspace_{id}/`. We'll save this archive twice under two names:
    * `initial.tar.gz`: the initial state (this can later be restored)
    * `current.tar.gz`: the "working" state of the workspace (this will be modified as the user interacts with the workspace)
  * Update workpace state to `stopped`
* Commit the transaction, thereby releasing the lock
* Send `change:state` websocket message to client
* Begin a new transaction
  * Obtain a lock on the row in the `workspaces` table
  * Allocate a host for this workspace's container
  * Instruct host to begin loading images, S3 resources, etc
  * Update workspace state to `launching`
* Commit the transaction, thereby releasing the lock
* Send `change:state` websocket message to client

#### Workspace is in state `stopped`

* Respond to the request with the basic markup for the outer frame
* [Do whole launch container thing from the above section here; let's write this out in more detail later]

#### Workspace is in state `launching` or `running`k

* Respond to the request with the basic markup for the outer frame

In either case, the client will recieve exactly the same outer frame markup. The "outer frame" will initially render a loading screen and set up a websocket connection to a PL server.

### Websocket protocol

This is explicitly modeled on the existing external grading websocket code (`externalGradingLiveUpdate.ejs`). All efforts should be made to keep the workspaces implementation of websockets consistent with the external grading implementation, as it has proved very robust in production.

* `init`: sent from client to server to request initial state.
* `change:state`: sent from server to client to inform it of a state change.

### State machine transitions

* `uninitialized` -> `stopped`: We have created S3 resources for this workspace.
* `stopped` -> `launching`: We are allocating a host for this workspace and loading the necessary image and S3 resources to the host.
* `launching` -> `running`: The container for the workspace is running and ready to serve requests.
* `launching` -> `stopped`: We failed to start a container for the workspace.
* `running` -> `stopped`: The container for the workspace has stopped and cannot serve requests.

## Notes

* Since PrairieLearn will be serving a bunch of different roles depending on context, PrairieLearn's `server.js` should be split up so that only code needed to serve a particular role is loaded. While we're refactoring, let's just make it better, do things async, etc.
* There’s a distinction between workspace state and submission state - the former can include arbitrary files, the latter just includes whatever the question specifies.
